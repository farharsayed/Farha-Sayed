# This is a complete configuration to deploy Loki backed by a s3-compatible API
# like MinIO for storage.
# Index files will be written locally at /loki/index and, eventually, will be shipped to the storage via tsdb-shipper.
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-config
  namespace: farhatemp
  labels:
    app: loki-simple-scalable

deploymentMode: SimpleScalable
# designed for medium to large environments

backend:
  replicas: 3
  affinity: {}
read:
  replicas: 3
  affinity: {}
write:
  replicas: 3
  affinity: {}

data:
  local-config.yml: |
    auth_enabled: false
    server:
      http_listen_port: 3105
      http_listen_network: "tcp"
      grpc_listen_port: 9095 
      # if we dont specify a grpc port, it automatically finds one to use for scheduler connection
      grpc_listen_network: "tcp"
      http_server_read_timeout: 600s
      http_server_write_timeout: 600s
    memberlist: 
      join_members: 
      - loki-ss-read:7946
      - loki-ss-write:7946
      - loki-ss-backend:7946
      abort_if_cluster_join_fails: false
      cluster_label: "loki"
      cluster_label_verification_disabled: true
      gossip_to_dead_nodes_time: 15s
      left_ingesters_timeout: 30s
      bind_port: 7946
      gossip_interval: 2s
      bind_addr: ['0.0.0.0']

    ingester:
    # specifying the type of encoding to use for compressing log data chunks
    # here, we use snappy (good balance between compression speed and efficiency)
    # other possible options (gzip, ls4, zstd)
      chunk_encoding: snappy
      index_shards: 32
      autoforget_unhealthy: true

      lifecycler:
        ring:
          kvstore:
            store: memberlist
            # or memberlist
            # or inmemory
          replication_factor: 1
      wal:
        enabled: true
        dir: /loki/wal 
      shutdown_marker_path: /loki/marker/shutdown
      
    querier:
      query_store_only: false
      query_ingesters_within: 0
      max_concurrent: 4 

    frontend: 
      log_queries_longer_than: -5s 

    index_gateway:
      mode: simple
      ring: 
        replication_factor: 1
    ruler: 
      enable_sharding: false
    query_range:
      parallelise_shardable_queries: false
    common:
      # number of instances need to be at least as many as replication factor
      replication_factor: 1
      instance_addr: ""
      
      storage:
        filesystem: null
        s3: 
          endpoint: <insert data>
          bucketnames: <insert data>
          access_key_id: <insert data>
          secret_access_key: <insert data>
          s3forcepathstyle: true
          http_config:
            insecure_skip_verify: true
            timeout: 300s
      ring:
        # kvstore is the backend storage to use for the ring 
        kvstore:
          store: memberlist
          # NOTE: inmemory only for testing
        heartbeat_period: 10s
        heartbeat_timeout: 2m
        #  heartbeat timeout after which compactors are considered unhealthy within the ring. 0 = never (timeout disabled).      
    storage_config:
      aws: 
          endpoint: <insert data>
          bucketnames: <insert data>
          # access_key_id: ${s3-access-key-id}
          # secret_access_key: ${s3-secret-access-key}
          access_key_id: <insert data>
          secret_access_key: <insert data>
          s3forcepathstyle: true
          http_config:
            insecure_skip_verify: true
      tsdb_shipper:
        active_index_directory: /data/loki/index
        cache_location: /data/loki/index-cache
        cache_ttl: 24h

    limits_config: 


      allow_structured_metadata: true      
      # FOR OTEL  
      # structured metadata is required because ingesting data in OTEL format, it's designed to support native ingestion of OTEL data
      # it's an antipattern to extract info that already exists in the log lines and put it into structured metadata 
      # structured metadata - way of attaching metadata to logs without iindexing them or including them in the log lin eocntext itself 
      # structured metadata is often used to query commonly needed metadata from log lines without needing to apply a parser every time 

      max_global_streams_per_user: 0
      # controls the maximum streams a single user can create across Loki 
      # 0 disables it

      # max_cache_freshness_per_query: 10m
      # # prevents very recent results that might still be in flux, from being cached

      # split_queries_by_interval: 15m
      # query_timeout: 5m
      # # timeout when querying backends (ingesters/storage) during execution of a query request
      # # default = 1m

      # volume_enabled: true
      # whether log volume endpoints are enabled 
      # commented off cause its true by default

      index_gateway_shard_size: 1
      # how many index gateways should be used by a tenant for querying 

      # ruler_tenant_shard_size: 0
      # 0 default,disabled

      ingestion_rate_mb: 10
      # per user ingestion rate limit in sample size per second
      # we had 14, default is 4
      ingestion_burst_size_mb: 30
      # needs to be at least the maximum logs size expected in a single push request
      per_stream_rate_limit: 10MB
      # default = 3MB

      max_query_length: 0
      # limits the length of chunk store queries, 0 disables it

      retention_period: 30d 
      # for compactor


    schema_config:
      configs:
        - from: 2024-08-06
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h

    table_manager: 
      retention_deletes_enabled: true
      retention_period: 48h


    compactor:
      compactor_ring: 
          kvstore: 
            store: memberlist
      # retention - loki will retain pre-compressed logs for 30d and then delete them, compacts them every 10 minutes 
      # retenton delete delay - past 30d, logs will only be kept for a max of 2h
      # if compaction interval is too small (1m) or retention period is too less (default is 0s cause retention is disabled by default) then its possible to prematurely delete logs, causing loss of logs 
      retention_enabled: true
      shared_store: s3
      working_directory: /loki/compactor
      delete_request_store: s3
      delete_max_interval: 24h
      compaction_interval: 10m
      retention_delete_delay: 2h
      retention_delete_worker_count: 150

    # Zero out replica counts of other deployment modes
singleBinary:
  replicas: 0
ingester:
  replicas: 0
querier:
  replicas: 0
queryFrontend:
  replicas: 0
queryScheduler:
  replicas: 0
distributor:
  replicas: 0
compactor:
  replicas: 0
indexGateway:
  replicas: 0
bloomCompactor:
  replicas: 0
bloomGateway:
  replicas: 0
